{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import math\n",
    "import optuna\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error \n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "import sys\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "RAND = 10\n",
    "N_FOLDS = 3\n",
    "\n",
    "backend_path = os.path.abspath('../backend')\n",
    "sys.path.append(backend_path)\n",
    "from get_metrics import get_metrics_regression\n",
    "from check_overfitting import check_overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Чтение DataFrame df в файл data/df.csv\n",
    "df = pd.read_csv('../data/df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[-50000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# основные описательные статистики для числовых признаков\n",
    "df.iloc[:, 1:].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# основные описательные статистики для булевых и категориальных признаков\n",
    "df.describe(include=[\"object\", \"bool\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# разделение данных train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# признаки\n",
    "X = df[['milliseconds', 'significance', 'country', 'depth', 'year', 'month', 'day', 'hour', 'minute', 'second']]\n",
    "\n",
    "# целевые переменные\n",
    "y = df[['magnitude', 'longitude', 'latitude']]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=RAND)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# создаем LabelEncoder для кодирования категориальных значений\n",
    "le = LabelEncoder()\n",
    "\n",
    "# обучаем le на тренировочных и тестовых данных\n",
    "le.fit(np.concatenate((X_train['country'], X_test['country'])))\n",
    "\n",
    "# кодирование колонки 'country' для обучения моделей\n",
    "X_train['country'] = le.transform(X_train['country'])\n",
    "X_test['country'] = le.transform(X_test['country'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# создаем объект scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# масштабируем признаки в X_train\n",
    "X_train[['milliseconds', 'depth', 'year', 'month', 'day', 'hour', 'minute', 'second']] = scaler.fit_transform(X_train[['milliseconds', 'depth', 'year', 'month', 'day', 'hour', 'minute', 'second']])\n",
    "\n",
    "# масштабируем признаки в X_test\n",
    "X_test[['milliseconds', 'depth', 'year', 'month', 'day', 'hour', 'minute', 'second']] = scaler.transform(X_test[['milliseconds', 'depth', 'year', 'month', 'day', 'hour', 'minute', 'second']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# модель RandomForestRegressor\n",
    "rfr = RandomForestRegressor(random_state=RAND)\n",
    "# обучаем модель\n",
    "rfr.fit(X_train, y_train)\n",
    "# предсказания на test \n",
    "y_pred_rfr = rfr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# проверка на переобучение модели RandomForestRegressor\n",
    "check_overfitting(rfr, X_train, y_train, X_test, y_test, mean_squared_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# просмотр метрик модели RandomForestRegressor обученной на train\n",
    "metrics = get_metrics_regression(y_test,\n",
    "                                 y_pred = y_pred_rfr,\n",
    "                                 X_test = X_test,\n",
    "                                 name='RandomForestRegressor_Baseline')\n",
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# модель DecisionTreeRegressor\n",
    "dtr = DecisionTreeRegressor(random_state=RAND)\n",
    "# обучаем модель\n",
    "dtr.fit(X_train, y_train)\n",
    "# предсказания на test \n",
    "y_pred_dtr = dtr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# проверка на переобучение модели DecisionTreeRegressor\n",
    "check_overfitting(dtr, X_train, y_train, X_test, y_test, mean_squared_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# просмотр метрик модели DecisionTreeRegressor обученной на train\n",
    "metrics = pd.concat([\n",
    "    metrics,\n",
    "    get_metrics_regression(y_test,\n",
    "                           y_pred = y_pred_dtr,\n",
    "                           X_test = X_test,\n",
    "                           name='DecisionTreeRegressor_Baseline')])\n",
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# модель GradientBoostingRegressor\n",
    "gbr = MultiOutputRegressor(GradientBoostingRegressor(random_state=RAND)) \n",
    "# обучаем модель\n",
    "gbr.fit(X_train, y_train)\n",
    "# предсказания на test \n",
    "y_pred_gbr = gbr.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# проверка на переобучение модели GradientBoostingRegressor\n",
    "check_overfitting(gbr, X_train, y_train, X_test, y_test, mean_squared_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# просмотр метрик модели GradientBoostingRegressor обученной на train\n",
    "metrics = pd.concat([\n",
    "    metrics,\n",
    "    get_metrics_regression(y_test,\n",
    "                           y_pred = y_pred_gbr,\n",
    "                           X_test = X_test,\n",
    "                           name='GradientBoostingRegressor_Baseline')])\n",
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNeighborsRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# модель KNeighborsRegressor\n",
    "knn = KNeighborsRegressor()\n",
    "# обучаем модель\n",
    "knn.fit(X_train, y_train)\n",
    "# предсказания на test \n",
    "y_pred_knn = knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# проверка на переобучение модели KNeighborsRegressor\n",
    "check_overfitting(knn, X_train, y_train, X_test, y_test, mean_squared_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# просмотр метрик модели KNeighborsRegressor обученной на train\n",
    "metrics = pd.concat([\n",
    "    metrics,\n",
    "    get_metrics_regression(y_test,\n",
    "                           y_pred = y_pred_knn,\n",
    "                           X_test = X_test,\n",
    "                           name='KNeighborsRegressor')])\n",
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optuna & KFold подбор гиперпараметров и кросс-валидация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# целевая функция для оптимизации\n",
    "def objective(trial):\n",
    "    # гиперпараметры для настройки\n",
    "    n_estimators = trial.suggest_int('n_estimators', 100, 1000)\n",
    "    max_depth = trial.suggest_int('max_depth', 5, 10)\n",
    "    min_samples_split = trial.suggest_int('min_samples_split', 2, 10)\n",
    "    min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 3)\n",
    "    min_weight_fraction_leaf = trial.suggest_float('min_weight_fraction_leaf', 0.0, 0.5)\n",
    "    max_features = trial.suggest_int('max_features', 1, 10)\n",
    "    bootstrap = trial.suggest_categorical('bootstrap', [True, False])\n",
    "\n",
    "    # RandomForestRegressor с гиперпараметрами\n",
    "    rfr = RandomForestRegressor(n_estimators=n_estimators,\n",
    "                                max_depth=max_depth,\n",
    "                                min_samples_split=min_samples_split,\n",
    "                                min_samples_leaf=min_samples_leaf,\n",
    "                                min_weight_fraction_leaf=min_weight_fraction_leaf,\n",
    "                                max_features=max_features,\n",
    "                                bootstrap=bootstrap,\n",
    "                                random_state=RAND)\n",
    "\n",
    "    # выполнение кросс-валидации\n",
    "    scores = cross_val_score(rfr, X_train, y_train, cv=KFold(n_splits=N_FOLDS, shuffle=True, random_state=RAND))\n",
    "    score = np.mean(scores)\n",
    "\n",
    "    return -score  # Optuna минимизирует целевую функцию, поэтому мы используем -score\n",
    "\n",
    "# выполнение настройки гиперпараметров с Optuna\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=100, timeout=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# получение лучших гиперпараметров\n",
    "best_params_rfr = study.best_params\n",
    "\n",
    "# создание RandomForestRegressor с лучшими гиперпараметрами\n",
    "rfr_best_params = RandomForestRegressor(**best_params_rfr, random_state=RAND)\n",
    "\n",
    "# обучение модели\n",
    "rfr_best_params.fit(X_train, y_train)\n",
    "\n",
    "# предсказания на тестовой выборке\n",
    "y_pred_rfr_best_params = rfr_best_params.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# оценка модели\n",
    "check_overfitting(rfr_best_params, X_train, y_train, X_test, y_test, mean_squared_error)\n",
    "\n",
    "# получение метрик\n",
    "metrics = pd.concat([\n",
    "    metrics,\n",
    "    get_metrics_regression(y_test,\n",
    "                           y_pred=y_pred_rfr_best_params,\n",
    "                           X_test=X_test,\n",
    "                           name='RandomForestRegressor_best_params_optuna')])\n",
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# целевая функция для оптимизации\n",
    "def objective(trial):\n",
    "    # гиперпараметры для настройки\n",
    "    splitter = trial.suggest_categorical('splitter', ['best', 'random'])\n",
    "    max_depth = trial.suggest_int('max_depth', 5, 10)\n",
    "    min_samples_split = trial.suggest_int('min_samples_split', 2, 10)\n",
    "    min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 3)\n",
    "    min_weight_fraction_leaf = trial.suggest_float('min_weight_fraction_leaf', 0.0, 0.5)\n",
    "    max_features = trial.suggest_int('max_features', 1, 10)\n",
    "    max_leaf_nodes = trial.suggest_int('max_leaf_nodes', 2, 5)\n",
    "\n",
    "    # DecisionTreeRegressor с гиперпараметрами\n",
    "    rfr = DecisionTreeRegressor(splitter=splitter,\n",
    "                                max_depth=max_depth,\n",
    "                                min_samples_split=min_samples_split,\n",
    "                                min_samples_leaf=min_samples_leaf,\n",
    "                                min_weight_fraction_leaf=min_weight_fraction_leaf,\n",
    "                                max_features=max_features,\n",
    "                                max_leaf_nodes=max_leaf_nodes,\n",
    "                                random_state=RAND)\n",
    "\n",
    "    # выполнение кросс-валидации\n",
    "    scores = cross_val_score(rfr, X_train, y_train, cv=KFold(n_splits=N_FOLDS, shuffle=True, random_state=RAND))\n",
    "    score = np.mean(scores)\n",
    "\n",
    "    return -score  # Optuna минимизирует целевую функцию, поэтому мы используем -score\n",
    "\n",
    "# выполнение настройки гиперпараметров с Optuna\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=100, timeout=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# получение лучших гиперпараметров\n",
    "best_params_dtr = study.best_params\n",
    "\n",
    "# создание RandomForestRegressor с лучшими гиперпараметрами\n",
    "dtr_best_params = DecisionTreeRegressor(**best_params_dtr, random_state=RAND)\n",
    "\n",
    "# обучение модели\n",
    "dtr_best_params.fit(X_train, y_train)\n",
    "\n",
    "# предсказания на тестовой выборке\n",
    "y_pred_dtr_best_params = dtr_best_params.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# оценка модели\n",
    "check_overfitting(dtr_best_params, X_train, y_train, X_test, y_test, mean_squared_error)\n",
    "\n",
    "# получение метрик\n",
    "metrics = pd.concat([\n",
    "    metrics,\n",
    "    get_metrics_regression(y_test,\n",
    "                           y_pred=y_pred_dtr_best_params,\n",
    "                           X_test=X_test,\n",
    "                           name='DecisionTreeRegressor_best_params_optuna')])\n",
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# целевая функция для оптимизации\n",
    "def objective(trial):\n",
    "    # гиперпараметры для настройки\n",
    "    learning_rate = trial.suggest_float('estimator__learning_rate', 0, 1)\n",
    "    n_estimators = trial.suggest_int('estimator__n_estimators', 100, 1000)\n",
    "    subsample = trial.suggest_float('estimator__subsample', 0.1, 1.0)\n",
    "    min_samples_split = trial.suggest_int('estimator__min_samples_split', 2, 10)\n",
    "    min_samples_leaf = trial.suggest_int('estimator__min_samples_leaf', 1, 5)\n",
    "    min_weight_fraction_leaf = trial.suggest_float('estimator__min_weight_fraction_leaf', 0.0, 0.5)\n",
    "    max_depth = trial.suggest_int('estimator__max_depth', 1, 10)\n",
    "\n",
    "    # GradientBoostingRegressor с гиперпараметрами\n",
    "    gbr = MultiOutputRegressor(GradientBoostingRegressor(learning_rate=learning_rate,\n",
    "                                                         n_estimators=n_estimators,\n",
    "                                                         subsample=subsample,\n",
    "                                                         min_samples_split=min_samples_split,\n",
    "                                                         min_samples_leaf=min_samples_leaf,\n",
    "                                                         min_weight_fraction_leaf=min_weight_fraction_leaf,\n",
    "                                                         max_depth=max_depth,\n",
    "                                                         random_state=RAND))\n",
    "\n",
    "    # выполнение кросс-валидации\n",
    "    scores = cross_val_score(gbr, X_train, y_train, cv=KFold(n_splits=N_FOLDS, shuffle=True, random_state=RAND))\n",
    "    score = np.mean(scores)\n",
    "\n",
    "    return -score  # Optuna минимизирует целевую функцию, поэтому мы используем -score\n",
    "\n",
    "# выполнение настройки гиперпараметров с Optuna\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=100, timeout=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# получение лучших гиперпараметров\n",
    "best_params_gbr = study.best_params\n",
    "\n",
    "# создание GradientBoostingRegressor с лучшими гиперпараметрами\n",
    "gbr_best_params = MultiOutputRegressor(GradientBoostingRegressor(**{k.replace('estimator__', ''): v for k, v in best_params_gbr.items()}, random_state=RAND))\n",
    "\n",
    "# обучение модели\n",
    "gbr_best_params.fit(X_train, y_train)\n",
    "\n",
    "# предсказания на тестовой выборке\n",
    "y_pred_gbr_best_params = gbr_best_params.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# оценка модели\n",
    "check_overfitting(gbr_best_params, X_train, y_train, X_test, y_test, mean_squared_error)\n",
    "\n",
    "# получение метрик\n",
    "metrics = pd.concat([\n",
    "    metrics,\n",
    "    get_metrics_regression(y_test,\n",
    "                           y_pred=y_pred_gbr_best_params,\n",
    "                           X_test=X_test,\n",
    "                           name='GradientBoostingRegressor_best_params_optuna')])\n",
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNeighborsRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# целевая функция для оптимизации\n",
    "def objective(trial):\n",
    "    # гиперпараметры для настройки\n",
    "    n_neighbors = trial.suggest_int('n_neighbors', 2, 10)\n",
    "    weights = trial.suggest_categorical('weights', ['uniform', 'distance'])\n",
    "    algorithm = trial.suggest_categorical('algorithm', ['brute', 'ball_tree', 'kd_tree'])\n",
    "    leaf_size = trial.suggest_int('leaf_size', 10, 50)\n",
    "    p = trial.suggest_int('p', 1, 5)\n",
    "    metric = trial.suggest_categorical('metric', ['euclidean', 'manhattan', 'minkowski'])\n",
    "\n",
    "    # KNeighborsRegressor с гиперпараметрами\n",
    "    knn = KNeighborsRegressor(n_neighbors=n_neighbors,\n",
    "                              weights=weights,\n",
    "                              algorithm=algorithm,\n",
    "                              leaf_size=leaf_size,\n",
    "                              p=p,\n",
    "                              metric=metric\n",
    "                              )\n",
    "\n",
    "    # выполнение кросс-валидации\n",
    "    scores = cross_val_score(knn, X_train, y_train, cv=KFold(n_splits=N_FOLDS, shuffle=True, random_state=RAND))\n",
    "    score = np.mean(scores)\n",
    "\n",
    "    return -score  # Optuna минимизирует целевую функцию, поэтому мы используем -score\n",
    "\n",
    "# выполнение настройки гиперпараметров с Optuna\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=100, timeout=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# получение лучших гиперпараметров\n",
    "best_params_knn = study.best_params\n",
    "\n",
    "# создание RandomForestRegressor с лучшими гиперпараметрами\n",
    "knn_best_params = KNeighborsRegressor(**best_params_knn)\n",
    "\n",
    "# обучение модели\n",
    "knn_best_params.fit(X_train, y_train)\n",
    "\n",
    "# предсказания на тестовой выборке\n",
    "y_pred_knn_best_params = knn_best_params.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# оценка модели\n",
    "check_overfitting(knn_best_params, X_train, y_train, X_test, y_test, mean_squared_error)\n",
    "\n",
    "# получение метрик\n",
    "metrics = pd.concat([\n",
    "    metrics,\n",
    "    get_metrics_regression(y_test,\n",
    "                           y_pred=y_pred_knn_best_params,\n",
    "                           X_test=X_test,\n",
    "                           name='KNeighborsRegressor_best_params_optuna')])\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Обратное преобразование масштабированных данных в X_train\n",
    "# X_train[['milliseconds', 'depth', 'year', 'month', 'day', 'hour', 'minute', 'second']] = scaler.inverse_transform(X_train[['milliseconds', 'depth', 'year', 'month', 'day', 'hour', 'minute', 'second']])\n",
    "\n",
    "# # Обратное преобразование масштабированных данных в X_test\n",
    "# X_test[['milliseconds', 'depth', 'year', 'month', 'day', 'hour', 'minute', 'second']] = scaler.inverse_transform(X_test[['milliseconds', 'depth', 'year', 'month', 'day', 'hour', 'minute', 'second']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# декодирование колонки 'country'\n",
    "#X_train['country'] = le.inverse_transform(X_train['country'])\n",
    "#X_test['country'] = le.inverse_transform(X_test['country'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
