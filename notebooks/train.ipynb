{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import math\n",
    "import optuna\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, KFold, cross_val_score\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error \n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "import sys\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "RAND = 10\n",
    "N_FOLDS = 3\n",
    "N_ITER = 300\n",
    "\n",
    "backend_path = os.path.abspath('../backend')\n",
    "sys.path.append(backend_path)\n",
    "from get_metrics import get_metrics_regression\n",
    "from check_overfitting import check_overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Чтение DataFrame df в файл data/df.csv\n",
    "df = pd.read_csv('../data/df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = df[-10000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>milliseconds</th>\n",
       "      <th>place</th>\n",
       "      <th>status</th>\n",
       "      <th>tsunami</th>\n",
       "      <th>significance</th>\n",
       "      <th>data_type</th>\n",
       "      <th>magnitude</th>\n",
       "      <th>country</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>depth</th>\n",
       "      <th>datetime</th>\n",
       "      <th>timezone</th>\n",
       "      <th>magnitude_bins</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>minute</th>\n",
       "      <th>second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1668773163070</td>\n",
       "      <td>14 km SSE of Eden Roc, Hawaii</td>\n",
       "      <td>automatic</td>\n",
       "      <td>0</td>\n",
       "      <td>58</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>1.94</td>\n",
       "      <td>USA</td>\n",
       "      <td>-155.030334</td>\n",
       "      <td>19.374001</td>\n",
       "      <td>7.10</td>\n",
       "      <td>2022-11-18 12:06:03</td>\n",
       "      <td>+00:00</td>\n",
       "      <td>green</td>\n",
       "      <td>2022</td>\n",
       "      <td>11</td>\n",
       "      <td>18</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1668773284487</td>\n",
       "      <td>40 km ESE of Nikolski, Alaska</td>\n",
       "      <td>reviewed</td>\n",
       "      <td>0</td>\n",
       "      <td>62</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>2.00</td>\n",
       "      <td>USA</td>\n",
       "      <td>-168.310800</td>\n",
       "      <td>52.786100</td>\n",
       "      <td>64.90</td>\n",
       "      <td>2022-11-18 12:08:04</td>\n",
       "      <td>+00:00</td>\n",
       "      <td>green</td>\n",
       "      <td>2022</td>\n",
       "      <td>11</td>\n",
       "      <td>18</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1668773482790</td>\n",
       "      <td>45 km SW of Howell, Utah</td>\n",
       "      <td>reviewed</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>1.16</td>\n",
       "      <td>USA</td>\n",
       "      <td>-112.845833</td>\n",
       "      <td>41.512167</td>\n",
       "      <td>5.73</td>\n",
       "      <td>2022-11-18 12:11:22</td>\n",
       "      <td>+00:00</td>\n",
       "      <td>green</td>\n",
       "      <td>2022</td>\n",
       "      <td>11</td>\n",
       "      <td>18</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    milliseconds                          place     status  tsunami   \n",
       "0  1668773163070  14 km SSE of Eden Roc, Hawaii  automatic        0  \\\n",
       "1  1668773284487  40 km ESE of Nikolski, Alaska   reviewed        0   \n",
       "2  1668773482790       45 km SW of Howell, Utah   reviewed        0   \n",
       "\n",
       "   significance   data_type  magnitude country   longitude   latitude  depth   \n",
       "0            58  earthquake       1.94     USA -155.030334  19.374001   7.10  \\\n",
       "1            62  earthquake       2.00     USA -168.310800  52.786100  64.90   \n",
       "2            21  earthquake       1.16     USA -112.845833  41.512167   5.73   \n",
       "\n",
       "              datetime timezone magnitude_bins  year  month  day  hour   \n",
       "0  2022-11-18 12:06:03   +00:00          green  2022     11   18    12  \\\n",
       "1  2022-11-18 12:08:04   +00:00          green  2022     11   18    12   \n",
       "2  2022-11-18 12:11:22   +00:00          green  2022     11   18    12   \n",
       "\n",
       "   minute  second  \n",
       "0       6       3  \n",
       "1       8       4  \n",
       "2      11      22  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 94354 entries, 0 to 94353\n",
      "Data columns (total 20 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   milliseconds    94354 non-null  int64  \n",
      " 1   place           94354 non-null  object \n",
      " 2   status          94354 non-null  object \n",
      " 3   tsunami         94354 non-null  int64  \n",
      " 4   significance    94354 non-null  int64  \n",
      " 5   data_type       94354 non-null  object \n",
      " 6   magnitude       94354 non-null  float64\n",
      " 7   country         94354 non-null  object \n",
      " 8   longitude       94354 non-null  float64\n",
      " 9   latitude        94354 non-null  float64\n",
      " 10  depth           94354 non-null  float64\n",
      " 11  datetime        94354 non-null  object \n",
      " 12  timezone        94354 non-null  object \n",
      " 13  magnitude_bins  94354 non-null  object \n",
      " 14  year            94354 non-null  int64  \n",
      " 15  month           94354 non-null  int64  \n",
      " 16  day             94354 non-null  int64  \n",
      " 17  hour            94354 non-null  int64  \n",
      " 18  minute          94354 non-null  int64  \n",
      " 19  second          94354 non-null  int64  \n",
      "dtypes: float64(4), int64(9), object(7)\n",
      "memory usage: 14.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tsunami</th>\n",
       "      <th>significance</th>\n",
       "      <th>magnitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>depth</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>minute</th>\n",
       "      <th>second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>94354.000000</td>\n",
       "      <td>94354.000000</td>\n",
       "      <td>94354.000000</td>\n",
       "      <td>94354.000000</td>\n",
       "      <td>94354.000000</td>\n",
       "      <td>94354.000000</td>\n",
       "      <td>94354.000000</td>\n",
       "      <td>94354.000000</td>\n",
       "      <td>94354.000000</td>\n",
       "      <td>94354.000000</td>\n",
       "      <td>94354.000000</td>\n",
       "      <td>94354.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.000964</td>\n",
       "      <td>67.406363</td>\n",
       "      <td>1.720177</td>\n",
       "      <td>-116.542011</td>\n",
       "      <td>41.560005</td>\n",
       "      <td>26.813648</td>\n",
       "      <td>2022.824915</td>\n",
       "      <td>5.299479</td>\n",
       "      <td>15.482046</td>\n",
       "      <td>11.486010</td>\n",
       "      <td>29.419537</td>\n",
       "      <td>29.468290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.031041</td>\n",
       "      <td>96.398645</td>\n",
       "      <td>1.178204</td>\n",
       "      <td>72.358151</td>\n",
       "      <td>20.357130</td>\n",
       "      <td>56.179701</td>\n",
       "      <td>0.380042</td>\n",
       "      <td>3.429028</td>\n",
       "      <td>8.635858</td>\n",
       "      <td>6.920763</td>\n",
       "      <td>17.357370</td>\n",
       "      <td>17.283395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-179.998700</td>\n",
       "      <td>-65.425400</td>\n",
       "      <td>-3.740000</td>\n",
       "      <td>2022.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>-153.445775</td>\n",
       "      <td>34.018333</td>\n",
       "      <td>3.400000</td>\n",
       "      <td>2023.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>15.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>1.400000</td>\n",
       "      <td>-122.852500</td>\n",
       "      <td>39.246300</td>\n",
       "      <td>9.200000</td>\n",
       "      <td>2023.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>29.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>2.100000</td>\n",
       "      <td>-116.717375</td>\n",
       "      <td>58.264000</td>\n",
       "      <td>25.600000</td>\n",
       "      <td>2023.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>44.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>2910.000000</td>\n",
       "      <td>7.800000</td>\n",
       "      <td>179.999400</td>\n",
       "      <td>86.593900</td>\n",
       "      <td>681.238000</td>\n",
       "      <td>2023.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>59.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            tsunami  significance     magnitude     longitude      latitude   \n",
       "count  94354.000000  94354.000000  94354.000000  94354.000000  94354.000000  \\\n",
       "mean       0.000964     67.406363      1.720177   -116.542011     41.560005   \n",
       "std        0.031041     96.398645      1.178204     72.358151     20.357130   \n",
       "min        0.000000      0.000000      0.000000   -179.998700    -65.425400   \n",
       "25%        0.000000     14.000000      0.950000   -153.445775     34.018333   \n",
       "50%        0.000000     30.000000      1.400000   -122.852500     39.246300   \n",
       "75%        0.000000     68.000000      2.100000   -116.717375     58.264000   \n",
       "max        1.000000   2910.000000      7.800000    179.999400     86.593900   \n",
       "\n",
       "              depth          year         month           day          hour   \n",
       "count  94354.000000  94354.000000  94354.000000  94354.000000  94354.000000  \\\n",
       "mean      26.813648   2022.824915      5.299479     15.482046     11.486010   \n",
       "std       56.179701      0.380042      3.429028      8.635858      6.920763   \n",
       "min       -3.740000   2022.000000      1.000000      1.000000      0.000000   \n",
       "25%        3.400000   2023.000000      3.000000      8.000000      6.000000   \n",
       "50%        9.200000   2023.000000      5.000000     16.000000     11.000000   \n",
       "75%       25.600000   2023.000000      7.000000     23.000000     17.000000   \n",
       "max      681.238000   2023.000000     12.000000     30.000000     23.000000   \n",
       "\n",
       "             minute        second  \n",
       "count  94354.000000  94354.000000  \n",
       "mean      29.419537     29.468290  \n",
       "std       17.357370     17.283395  \n",
       "min        0.000000      0.000000  \n",
       "25%       14.000000     15.000000  \n",
       "50%       29.000000     29.000000  \n",
       "75%       45.000000     44.000000  \n",
       "max       59.000000     59.000000  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# основные описательные статистики для числовых признаков\n",
    "df.iloc[:, 1:].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>place</th>\n",
       "      <th>status</th>\n",
       "      <th>data_type</th>\n",
       "      <th>country</th>\n",
       "      <th>datetime</th>\n",
       "      <th>timezone</th>\n",
       "      <th>magnitude_bins</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>94354</td>\n",
       "      <td>94354</td>\n",
       "      <td>94354</td>\n",
       "      <td>94354</td>\n",
       "      <td>94354</td>\n",
       "      <td>94354</td>\n",
       "      <td>94354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>34095</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>234</td>\n",
       "      <td>93284</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>8km NW of The Geysers, CA</td>\n",
       "      <td>reviewed</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>USA</td>\n",
       "      <td>2023-03-02 18:11:07</td>\n",
       "      <td>+00:00</td>\n",
       "      <td>green</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>973</td>\n",
       "      <td>84325</td>\n",
       "      <td>92210</td>\n",
       "      <td>80057</td>\n",
       "      <td>2</td>\n",
       "      <td>94354</td>\n",
       "      <td>82184</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            place    status   data_type country   \n",
       "count                       94354     94354       94354   94354  \\\n",
       "unique                      34095         3           7     234   \n",
       "top     8km NW of The Geysers, CA  reviewed  earthquake     USA   \n",
       "freq                          973     84325       92210   80057   \n",
       "\n",
       "                   datetime timezone magnitude_bins  \n",
       "count                 94354    94354          94354  \n",
       "unique                93284        1              3  \n",
       "top     2023-03-02 18:11:07   +00:00          green  \n",
       "freq                      2    94354          82184  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# основные описательные статистики для булевых и категориальных признаков\n",
    "df.describe(include=[\"object\", \"bool\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# разделение данных train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# признаки\n",
    "X = df[['milliseconds', 'significance', 'country', 'depth', 'year', 'month', 'day', 'hour', 'minute', 'second']]\n",
    "\n",
    "# целевые переменные\n",
    "y = df[['magnitude', 'longitude', 'latitude']]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=RAND)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# создаем LabelEncoder для кодирования категориальных значений\n",
    "le = LabelEncoder()\n",
    "\n",
    "# обучаем le на тренировочных и тестовых данных\n",
    "le.fit(np.concatenate((X_train['country'], X_test['country'])))\n",
    "\n",
    "# кодирование колонки 'country' для обучения моделей\n",
    "X_train['country'] = le.transform(X_train['country'])\n",
    "X_test['country'] = le.transform(X_test['country'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# создаем объект scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# масштабируем признаки в X_train\n",
    "X_train[['milliseconds', 'depth', 'year', 'month', 'day', 'hour', 'minute', 'second']] = scaler.fit_transform(X_train[['milliseconds', 'depth', 'year', 'month', 'day', 'hour', 'minute', 'second']])\n",
    "\n",
    "# масштабируем признаки в X_test\n",
    "X_test[['milliseconds', 'depth', 'year', 'month', 'day', 'hour', 'minute', 'second']] = scaler.transform(X_test[['milliseconds', 'depth', 'year', 'month', 'day', 'hour', 'minute', 'second']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# модель RandomForestRegressor\n",
    "rfr = RandomForestRegressor(random_state=RAND)\n",
    "# обучаем модель\n",
    "rfr.fit(X_train, y_train)\n",
    "# предсказания на test \n",
    "y_pred_rfr = rfr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# проверка на переобучение модели RandomForestRegressor\n",
    "check_overfitting(rfr, X_train, y_train, X_test, y_test, mean_squared_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# просмотр метрик модели RandomForestRegressor обученной на train\n",
    "metrics = get_metrics_regression(y_test,\n",
    "                                 y_pred = y_pred_rfr,\n",
    "                                 X_test = X_test,\n",
    "                                 name='RandomForestRegressor_Baseline')\n",
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# модель DecisionTreeRegressor\n",
    "dtr = DecisionTreeRegressor(random_state=RAND)\n",
    "# обучаем модель\n",
    "dtr.fit(X_train, y_train)\n",
    "# предсказания на test \n",
    "y_pred_dtr = dtr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# проверка на переобучение модели DecisionTreeRegressor\n",
    "check_overfitting(dtr, X_train, y_train, X_test, y_test, mean_squared_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# просмотр метрик модели DecisionTreeRegressor обученной на train\n",
    "metrics = pd.concat([\n",
    "    metrics,\n",
    "    get_metrics_regression(y_test,\n",
    "                           y_pred = y_pred_dtr,\n",
    "                           X_test = X_test,\n",
    "                           name='DecisionTreeRegressor_Baseline')])\n",
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# модель GradientBoostingRegressor\n",
    "gbr = MultiOutputRegressor(GradientBoostingRegressor(random_state=RAND)) \n",
    "# обучаем модель\n",
    "gbr.fit(X_train, y_train)\n",
    "# предсказания на test \n",
    "y_pred_gbr = gbr.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# проверка на переобучение модели GradientBoostingRegressor\n",
    "check_overfitting(gbr, X_train, y_train, X_test, y_test, mean_squared_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# просмотр метрик модели GradientBoostingRegressor обученной на train\n",
    "metrics = pd.concat([\n",
    "    metrics,\n",
    "    get_metrics_regression(y_test,\n",
    "                           y_pred = y_pred_gbr,\n",
    "                           X_test = X_test,\n",
    "                           name='GradientBoostingRegressor_Baseline')])\n",
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNeighborsRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# модель KNeighborsRegressor\n",
    "knn = KNeighborsRegressor(n_neighbors=5)\n",
    "# обучаем модель\n",
    "knn.fit(X_train, y_train)\n",
    "# предсказания на test \n",
    "y_pred_knn = knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# проверка на переобучение модели KNeighborsRegressor\n",
    "check_overfitting(knn, X_train, y_train, X_test, y_test, mean_squared_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# просмотр метрик модели KNeighborsRegressor обученной на train\n",
    "metrics = pd.concat([\n",
    "    metrics,\n",
    "    get_metrics_regression(y_test,\n",
    "                           y_pred = y_pred_knn,\n",
    "                           X_test = X_test,\n",
    "                           name='KNeighborsRegressor')])\n",
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optuna & KFold подбор гиперпараметров и кросс-валидация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # сетка параметров\n",
    "# param_grid = {\n",
    "#     'n_estimators': [100, 500, 1000],\n",
    "#     'max_depth': [None, 5, 10],\n",
    "#     'min_samples_split': [2, 5, 10],\n",
    "#     'min_samples_leaf': [1, 2, 3],\n",
    "#     'min_weight_fraction_leaf': [0.0, 0.1, 0.5],\n",
    "#     'max_features': [1 , 5 , 10],\n",
    "#     'bootstrap': [True, False],\n",
    "# }\n",
    "\n",
    "# # расчет количества моделей\n",
    "# num_models = math.prod(len(values) for values in param_grid.values())\n",
    "\n",
    "# print(f\"Количество моделей для обучения: {num_models}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # модель RandomForestRegressor\n",
    "# rfr = RandomForestRegressor(random_state=RAND)\n",
    "\n",
    "# # Создание KFold\n",
    "# kf = KFold(n_splits=N_FOLDS, shuffle=True, random_state=RAND)\n",
    "\n",
    "# # модель GridSearchCV\n",
    "# gsCV = GridSearchCV(rfr, param_grid, cv=kf, error_score='raise')\n",
    "\n",
    "# # производим обучение по сетке\n",
    "# gsCV.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # просмотр параметров\n",
    "# best_params_rfr = gsCV.best_params_\n",
    "# print(best_params_rfr)\n",
    "# print(gsCV.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # модель RandomForestRegressor с лучшими параметрами\n",
    "# rfr_best_params = RandomForestRegressor(**best_params_rfr, random_state=RAND)\n",
    "# # обучаем модель\n",
    "# rfr_best_params.fit(X_train, y_train)\n",
    "# # предсказания на test \n",
    "# y_pred_rfr_best_params = rfr_best_params.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # проверка на переобучение модели RandomForestRegressor с лучшими параметрами\n",
    "# check_overfitting(rfr_best_params, X_train, y_train, X_test, y_test, mean_squared_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # просмотр метрик модели RandomForestRegressor обученной на train с лучшими параметрами\n",
    "# metrics = pd.concat([\n",
    "#     metrics,\n",
    "#     get_metrics_regression(y_test,\n",
    "#                            y_pred = y_pred_rfr_best_params,\n",
    "#                            X_test = X_test,\n",
    "#                            name='RandomForestRegressor_best_params')])\n",
    "# metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# целевая функция для оптимизации\n",
    "def objective(trial):\n",
    "    # гиперпараметры для настройки\n",
    "    n_estimators = trial.suggest_int('n_estimators', 100, 1000)\n",
    "    max_depth = trial.suggest_int('max_depth', 5, 10)\n",
    "    min_samples_split = trial.suggest_int('min_samples_split', 2, 10)\n",
    "    min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 3)\n",
    "    min_weight_fraction_leaf = trial.suggest_uniform('min_weight_fraction_leaf', 0.0, 0.5)\n",
    "    max_features = trial.suggest_int('max_features', 1, 10)\n",
    "    bootstrap = trial.suggest_categorical('bootstrap', [True, False])\n",
    "\n",
    "    # RandomForestRegressor с гиперпараметрами\n",
    "    rfr = RandomForestRegressor(n_estimators=n_estimators,\n",
    "                                max_depth=max_depth,\n",
    "                                min_samples_split=min_samples_split,\n",
    "                                min_samples_leaf=min_samples_leaf,\n",
    "                                min_weight_fraction_leaf=min_weight_fraction_leaf,\n",
    "                                max_features=max_features,\n",
    "                                bootstrap=bootstrap,\n",
    "                                random_state=RAND)\n",
    "\n",
    "    # выполнение кросс-валидации\n",
    "    scores = cross_val_score(rfr, X_train, y_train, cv=KFold(n_splits=N_FOLDS, shuffle=True, random_state=RAND))\n",
    "    score = np.mean(scores)\n",
    "\n",
    "    return -score  # Optuna минимизирует целевую функцию, поэтому мы используем -score\n",
    "\n",
    "# выполнение настройки гиперпараметров с Optuna\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=100, timeout=2400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# получение лучших гиперпараметров\n",
    "best_params_rfr = study.best_params\n",
    "\n",
    "# создание RandomForestRegressor с лучшими гиперпараметрами\n",
    "rfr_best_params = RandomForestRegressor(**best_params_rfr, random_state=RAND)\n",
    "\n",
    "# обучение модели\n",
    "rfr_best_params.fit(X_train, y_train)\n",
    "\n",
    "# предсказания на тестовой выборке\n",
    "y_pred_rfr_best_params = rfr_best_params.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# оценка модели\n",
    "check_overfitting(rfr_best_params, X_train, y_train, X_test, y_test, mean_squared_error)\n",
    "\n",
    "# получение метрик\n",
    "metrics = pd.concat([\n",
    "    metrics,\n",
    "    get_metrics_regression(y_test,\n",
    "                           y_pred=y_pred_rfr_best_params,\n",
    "                           X_test=X_test,\n",
    "                           name='RandomForestRegressor_best_params_optuna')])\n",
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# целевая функция для оптимизации\n",
    "def objective(trial):\n",
    "    # гиперпараметры для настройки\n",
    "    splitter = trial.suggest_categorical('splitter', ['best', 'random'])\n",
    "    max_depth = trial.suggest_int('max_depth', 5, 10)\n",
    "    min_samples_split = trial.suggest_int('min_samples_split', 2, 10)\n",
    "    min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 3)\n",
    "    min_weight_fraction_leaf = trial.suggest_uniform('min_weight_fraction_leaf', 0.0, 0.5)\n",
    "    max_features = trial.suggest_int('max_features', 1, 10)\n",
    "    max_leaf_nodes = trial.suggest_int('max_leaf_nodes', 2, 5)\n",
    "\n",
    "    # DecisionTreeRegressor с гиперпараметрами\n",
    "    rfr = DecisionTreeRegressor(splitter=splitter,\n",
    "                                max_depth=max_depth,\n",
    "                                min_samples_split=min_samples_split,\n",
    "                                min_samples_leaf=min_samples_leaf,\n",
    "                                min_weight_fraction_leaf=min_weight_fraction_leaf,\n",
    "                                max_features=max_features,\n",
    "                                max_leaf_nodes=max_leaf_nodes,\n",
    "                                random_state=RAND)\n",
    "\n",
    "    # выполнение кросс-валидации\n",
    "    scores = cross_val_score(rfr, X_train, y_train, cv=KFold(n_splits=N_FOLDS, shuffle=True, random_state=RAND))\n",
    "    score = np.mean(scores)\n",
    "\n",
    "    return -score  # Optuna минимизирует целевую функцию, поэтому мы используем -score\n",
    "\n",
    "# выполнение настройки гиперпараметров с Optuna\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=100, timeout=2400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# получение лучших гиперпараметров\n",
    "best_params_dtr = study.best_params\n",
    "\n",
    "# создание RandomForestRegressor с лучшими гиперпараметрами\n",
    "dtr_best_params = DecisionTreeRegressor(**best_params_dtr, random_state=RAND)\n",
    "\n",
    "# обучение модели\n",
    "dtr_best_params.fit(X_train, y_train)\n",
    "\n",
    "# предсказания на тестовой выборке\n",
    "y_pred_dtr_best_params = dtr_best_params.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# оценка модели\n",
    "check_overfitting(dtr_best_params, X_train, y_train, X_test, y_test, mean_squared_error)\n",
    "\n",
    "# получение метрик\n",
    "metrics = pd.concat([\n",
    "    metrics,\n",
    "    get_metrics_regression(y_test,\n",
    "                           y_pred=y_pred_dtr_best_params,\n",
    "                           X_test=X_test,\n",
    "                           name='DecisionTreeRegressor_best_params_optuna')])\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # сетка параметров\n",
    "# param_grid = {\n",
    "#     'splitter': ['best', 'random'],\n",
    "#     'max_depth': [None, 5, 10],\n",
    "#     'min_samples_split': [2, 5, 10],\n",
    "#     'min_samples_leaf': [1, 2, 3],\n",
    "#     'min_weight_fraction_leaf': [0.0, 0.1, 0.5],\n",
    "#     'max_features': [1, 5, 10],\n",
    "#     'max_leaf_nodes':[None, 2, 5]\n",
    "# }\n",
    "\n",
    "# # расчет количества моделей\n",
    "# num_models = math.prod(len(values) for values in param_grid.values())\n",
    "\n",
    "# print(f\"Количество моделей для обучения: {num_models}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # модель DecisionTreeRegressor\n",
    "# dtr = DecisionTreeRegressor(random_state=RAND)\n",
    "\n",
    "# # Создание KFold\n",
    "# kf = KFold(n_splits=N_FOLDS, shuffle=True, random_state=RAND)\n",
    "\n",
    "# # модель GridSearchCV\n",
    "# gsCV = GridSearchCV(dtr, param_grid, cv=kf, error_score='raise')\n",
    "\n",
    "# # производим обучение по сетке\n",
    "# gsCV.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # просмотр параметров\n",
    "# best_params_dtr = gsCV.best_params_\n",
    "# print(best_params_dtr)\n",
    "# print(gsCV.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # модель DecisionTreeRegressor лучшими параметрами\n",
    "# dtr_best_params = DecisionTreeRegressor(**best_params_dtr, random_state=RAND)\n",
    "# # обучаем модель\n",
    "# dtr_best_params.fit(X_train, y_train)\n",
    "# # предсказания на test \n",
    "# y_pred_dtr_best_params = dtr_best_params.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # проверка на переобучение модели DecisionTreeRegressor с лучшими параметрами\n",
    "# check_overfitting(dtr_best_params, X_train, y_train, X_test, y_test, mean_squared_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # просмотр метрик модели DecisionTreeRegressor обученной на train с лучшими параметрами\n",
    "# metrics = pd.concat([\n",
    "#     metrics,\n",
    "#     get_metrics_regression(y_test,\n",
    "#                            y_pred = y_pred_dtr_best_params,\n",
    "#                            X_test = X_test,\n",
    "#                            name='DecisionTreeRegressor_best_params')])\n",
    "# metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# целевая функция для оптимизации\n",
    "def objective(trial):\n",
    "    # гиперпараметры для настройки\n",
    "    learning_rate = trial.suggest_categorical('estimator__learning_rate', [0, 0.1, 0.5, 1])\n",
    "    n_estimators = trial.suggest_categorical('estimator__n_estimators', [100, 500, 1000])\n",
    "    subsample = trial.suggest_categorical('estimator__subsample', [0.1, 0.5, 1.0])\n",
    "    min_samples_split = trial.suggest_categorical('estimator__min_samples_split', [2, 5, 10])\n",
    "    min_samples_leaf = trial.suggest_categorical('estimator__min_samples_leaf', [1, 2, 3])\n",
    "    min_weight_fraction_leaf = trial.suggest_categorical('estimator__min_weight_fraction_leaf', [0.0, 0.1, 0.5])\n",
    "    max_depth = trial.suggest_categorical('estimator__max_depth', [None, 5, 10])\n",
    "\n",
    "    # GradientBoostingRegressor с гиперпараметрами\n",
    "    gbr = MultiOutputRegressor(GradientBoostingRegressor(learning_rate=learning_rate,\n",
    "                                                         n_estimators=n_estimators,\n",
    "                                                         subsample=subsample,\n",
    "                                                         min_samples_split=min_samples_split,\n",
    "                                                         min_samples_leaf=min_samples_leaf,\n",
    "                                                         min_weight_fraction_leaf=min_weight_fraction_leaf,\n",
    "                                                         max_depth=max_depth,\n",
    "                                                         random_state=RAND))\n",
    "\n",
    "    # выполнение кросс-валидации\n",
    "    scores = cross_val_score(gbr, X_train, y_train, cv=KFold(n_splits=N_FOLDS, shuffle=True, random_state=RAND))\n",
    "    score = np.mean(scores)\n",
    "\n",
    "    return -score  # Optuna минимизирует целевую функцию, поэтому мы используем -score\n",
    "\n",
    "# выполнение настройки гиперпараметров с Optuna\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=5, timeout=2400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# получение лучших гиперпараметров\n",
    "best_params_gbr = study.best_params\n",
    "\n",
    "# создание GradientBoostingRegressor с лучшими гиперпараметрами\n",
    "gbr_best_params = MultiOutputRegressor(GradientBoostingRegressor(**{k.replace('estimator__', ''): v for k, v in best_params_gbr.items()}, random_state=RAND))\n",
    "\n",
    "# обучение модели\n",
    "gbr_best_params.fit(X_train, y_train)\n",
    "\n",
    "# предсказания на тестовой выборке\n",
    "y_pred_gbr_best_params = gbr_best_params.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# оценка модели\n",
    "check_overfitting(gbr_best_params, X_train, y_train, X_test, y_test, mean_squared_error)\n",
    "\n",
    "# получение метрик\n",
    "metrics = pd.concat([\n",
    "    metrics,\n",
    "    get_metrics_regression(y_test,\n",
    "                           y_pred=y_pred_gbr_best_params,\n",
    "                           X_test=X_test,\n",
    "                           name='GradientBoostingRegressor_best_params_optuna')])\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # сетка параметров\n",
    "# param_grid = {\n",
    "#     'estimator__learning_rate': [0,1, 0,5, 1],\n",
    "#     'estimator__n_estimators': [100, 500, 1000],\n",
    "#     'estimator__subsample': [0.1, 0.5, 1.0],\n",
    "#     'estimator__min_samples_split': [2, 5, 10],\n",
    "#     'estimator__min_samples_leaf': [1, 2, 3],\n",
    "#     'estimator__min_weight_fraction_leaf': [0.0, 0.1, 0.5],\n",
    "#     'estimator__max_depth': [None, 5, 10],\n",
    "# }\n",
    "\n",
    "# # расчет количества моделей\n",
    "# num_models = math.prod(len(values) for values in param_grid.values())\n",
    "\n",
    "# print(f\"Количество моделей для обучения: {num_models}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # модель GradientBoostingRegressor\n",
    "# gbr = MultiOutputRegressor(GradientBoostingRegressor(random_state=RAND))\n",
    "\n",
    "# # Создание KFold\n",
    "# kf = KFold(n_splits=N_FOLDS, shuffle=True, random_state=RAND)\n",
    "\n",
    "# # модель GridSearchCV\n",
    "# gsCV = GridSearchCV(gbr, param_grid, cv=kf, error_score='raise')\n",
    "\n",
    "# # производим обучение по сетке\n",
    "# gsCV.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # просмотр параметров\n",
    "# best_params_gbr = gsCV.best_params_\n",
    "# print(best_params_gbr)\n",
    "# print(gsCV.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # модель GradientBoostingRegressor лучшими параметрами\n",
    "# gbr_best_params = MultiOutputRegressor(GradientBoostingRegressor(**{k.replace('estimator__', ''): v for k, v in best_params_gbr.items()}, random_state=RAND))\n",
    "# # обучаем модель\n",
    "# gbr_best_params.fit(X_train, y_train)\n",
    "# # предсказания на test \n",
    "# y_pred_gbr_best_params = gbr_best_params.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # проверка на переобучение модели GradientBoostingRegressor с лучшими параметрами\n",
    "# check_overfitting(gbr_best_params, X_train, y_train, X_test, y_test, mean_squared_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # просмотр метрик модели GradientBoostingRegressor обученной на train с лучшими параметрами\n",
    "# metrics = pd.concat([\n",
    "#     metrics,\n",
    "#     get_metrics_regression(y_test,\n",
    "#                            y_pred = y_pred_gbr_best_params,\n",
    "#                            X_test = X_test,\n",
    "#                            name='GradientBoostingRegressor_best_params')])\n",
    "# metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNeighborsRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# целевая функция для оптимизации\n",
    "def objective(trial):\n",
    "    # гиперпараметры для настройки\n",
    "    n_neighbors = trial.suggest_int('n_neighbors', 2, 10)\n",
    "    weights = trial.suggest_categorical('weights', ['uniform', 'distance'])\n",
    "    algorithm = trial.suggest_categorical('algorithm', ['brute', 'ball_tree', 'kd_tree'])\n",
    "    leaf_size = trial.suggest_int('leaf_size', 10, 50)\n",
    "    p = trial.suggest_int('p', 1, 5)\n",
    "    metric = trial.suggest_categorical('metric', ['euclidean', 'manhattan', 'minkowski'])\n",
    "\n",
    "    # KNeighborsRegressor с гиперпараметрами\n",
    "    knn = KNeighborsRegressor(n_neighbors=n_neighbors,\n",
    "                              weights=weights,\n",
    "                              algorithm=algorithm,\n",
    "                              leaf_size=leaf_size,\n",
    "                              p=p,\n",
    "                              metric=metric)\n",
    "\n",
    "    # выполнение кросс-валидации\n",
    "    scores = cross_val_score(knn, X_train, y_train, cv=KFold(n_splits=N_FOLDS, shuffle=True, random_state=RAND))\n",
    "    score = np.mean(scores)\n",
    "\n",
    "    return -score  # Optuna минимизирует целевую функцию, поэтому мы используем -score\n",
    "\n",
    "# выполнение настройки гиперпараметров с Optuna\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=100, timeout=2400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# получение лучших гиперпараметров\n",
    "best_params_knn = study.best_params\n",
    "\n",
    "# создание RandomForestRegressor с лучшими гиперпараметрами\n",
    "knn_best_params = KNeighborsRegressor(**best_params_knn)\n",
    "\n",
    "# обучение модели\n",
    "knn_best_params.fit(X_train, y_train)\n",
    "\n",
    "# предсказания на тестовой выборке\n",
    "y_pred_knn_best_params = knn_best_params.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# оценка модели\n",
    "check_overfitting(knn_best_params, X_train, y_train, X_test, y_test, mean_squared_error)\n",
    "\n",
    "# получение метрик\n",
    "metrics = pd.concat([\n",
    "    metrics,\n",
    "    get_metrics_regression(y_test,\n",
    "                           y_pred=y_pred_knn_best_params,\n",
    "                           X_test=X_test,\n",
    "                           name='KNeighborsRegressor_best_params_optuna')])\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # сетка параметров\n",
    "# param_grid = {\n",
    "#     'n_neighbors': [2, 5, 10],\n",
    "#     'weights': ['uniform', 'distance'],\n",
    "#     'algorithm': ['brute', 'ball_tree', 'kd_tree'],\n",
    "#     'leaf_size': [10, 30, 50],\n",
    "#     'p': [1, 2, 5],\n",
    "#     'metric': ['cosine', 'euclidean', 'manhattan', 'minkowski'],\n",
    "# }\n",
    "\n",
    "# # расчет количества моделей\n",
    "# num_models = math.prod(len(values) for values in param_grid.values())\n",
    "\n",
    "# print(f\"Количество моделей для обучения: {num_models}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # модель KNeighborsRegressor\n",
    "# knn = KNeighborsRegressor()\n",
    "\n",
    "# # Создание KFold\n",
    "# kf = KFold(n_splits=N_FOLDS, shuffle=True, random_state=RAND)\n",
    "\n",
    "# # модель GridSearchCV\n",
    "# gsCV = GridSearchCV(knn, param_grid, cv=kf, error_score='raise')\n",
    "\n",
    "# # производим обучение по сетке\n",
    "# gsCV.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # просмотр параметров\n",
    "# best_params_knn = gsCV.best_params_\n",
    "# print(best_params_knn)\n",
    "# print(gsCV.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # модель KNeighborsRegressor лучшими параметрами\n",
    "# knn_best_params = KNeighborsRegressor(**best_params_knn)\n",
    "# # обучаем модель\n",
    "# knn_best_params.fit(X_train, y_train)\n",
    "# # предсказания на test \n",
    "# y_pred_knn_best_params = knn_best_params.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # проверка на переобучение модели KNeighborsRegressor с лучшими параметрами\n",
    "# check_overfitting(knn_best_params, X_train, y_train, X_test, y_test, mean_squared_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # просмотр метрик модели KNeighborsRegressor обученной на train с лучшими параметрами\n",
    "# metrics = pd.concat([\n",
    "#     metrics,\n",
    "#     get_metrics_regression(y_test,\n",
    "#                            y_pred = y_pred_knn_best_params,\n",
    "#                            X_test = X_test,\n",
    "#                            name='KNeighborsRegressor_best_params')])\n",
    "# metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Обратное преобразование масштабированных данных в X_train\n",
    "# X_train[['milliseconds', 'depth', 'year', 'month', 'day', 'hour', 'minute', 'second']] = scaler.inverse_transform(X_train[['milliseconds', 'depth', 'year', 'month', 'day', 'hour', 'minute', 'second']])\n",
    "\n",
    "# # Обратное преобразование масштабированных данных в X_test\n",
    "# X_test[['milliseconds', 'depth', 'year', 'month', 'day', 'hour', 'minute', 'second']] = scaler.inverse_transform(X_test[['milliseconds', 'depth', 'year', 'month', 'day', 'hour', 'minute', 'second']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# декодирование колонки 'country'\n",
    "#X_train['country'] = le.inverse_transform(X_train['country'])\n",
    "#X_test['country'] = le.inverse_transform(X_test['country'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
